{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "22d5be3d-4fed-4ef6-b71b-2b06ba552fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b1c05aba-d201-4ce4-98c9-4deb2eee178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Admin\\Downloads\\student_admission_record_dirty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6087e3c2-7661-4d5a-bdd1-3844f3eb4ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Admission Test Score</th>\n",
       "      <th>High School Percentage</th>\n",
       "      <th>City</th>\n",
       "      <th>Admission Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shehroz</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>68.90</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waqar</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.73</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bushra</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islamabad</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aliya</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>55.0</td>\n",
       "      <td>85.29</td>\n",
       "      <td>Karachi</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bilal</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>61.13</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Ali</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.09</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Bilal</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>84.40</td>\n",
       "      <td>Islamabad</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Fatima</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>50.86</td>\n",
       "      <td>Multan</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Shoaib</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>91.0</td>\n",
       "      <td>80.12</td>\n",
       "      <td>Quetta</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Maaz</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>88.0</td>\n",
       "      <td>86.85</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>Accepted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name   Age  Gender  Admission Test Score  High School Percentage  \\\n",
       "0    Shehroz  24.0  Female                  50.0                   68.90   \n",
       "1      Waqar  21.0  Female                  99.0                   60.73   \n",
       "2     Bushra  17.0    Male                  89.0                     NaN   \n",
       "3      Aliya  17.0    Male                  55.0                   85.29   \n",
       "4      Bilal  20.0    Male                  65.0                   61.13   \n",
       "..       ...   ...     ...                   ...                     ...   \n",
       "152      Ali  19.0  Female                  85.0                   78.09   \n",
       "153    Bilal  17.0  Female                  81.0                   84.40   \n",
       "154   Fatima  21.0  Female                  98.0                   50.86   \n",
       "155   Shoaib  -1.0    Male                  91.0                   80.12   \n",
       "156     Maaz  17.0    Male                  88.0                   86.85   \n",
       "\n",
       "          City Admission Status  \n",
       "0       Quetta         Rejected  \n",
       "1      Karachi              NaN  \n",
       "2    Islamabad         Accepted  \n",
       "3      Karachi         Rejected  \n",
       "4       Lahore              NaN  \n",
       "..         ...              ...  \n",
       "152     Quetta         Accepted  \n",
       "153  Islamabad         Rejected  \n",
       "154     Multan         Accepted  \n",
       "155     Quetta         Accepted  \n",
       "156     Lahore         Accepted  \n",
       "\n",
       "[157 rows x 7 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab3fb193-4a48-4733-bf2d-9c43e6c63acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                      10\n",
       "Age                       10\n",
       "Gender                    10\n",
       "Admission Test Score      11\n",
       "High School Percentage    11\n",
       "City                      10\n",
       "Admission Status          10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "63fa0806-0db1-4fba-9906-0f7339649e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ed7fb1d7-5eef-4c27-bafb-39a1bb1d816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Age\"]<0,\"Age\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7ca9f0c2-d93c-47bf-a32f-cf73ef65aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Admission Status\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f1c121a0-7ae8-4071-b618-4b387f202967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"Admission Status\")\n",
    "y = df[\"Admission Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1a5d6f43-2bc5-440e-8567-d8470dae1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "y_encoded = label.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1476978a-8716-4c5e-89af-5f95d7b21080",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Age\",\"Admission Test Score\",\"High School Percentage\"]\n",
    "cat_cols = [\"Gender\",\"City\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3e36e637-461f-4574-abeb-be041eed008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "col_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "df[cat_cols] = col_imputer.fit_transform(df[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b9ddb61a-691c-4bd0-94f2-75ade9463298",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\",StandardScaler(),num_cols),\n",
    "        (\"cat\",OneHotEncoder(drop=\"first\"),cat_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cdd3c202-daf7-41ec-8eaf-32dc3cef6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val,X_test,y_train_val,y_test = train_test_split(X,y_encoded,test_size=0.2,stratify=y_encoded)\n",
    "\n",
    "test_size = 0.2\n",
    "size_ratio = test_size / (1-0.2)\n",
    "\n",
    "X_train, X_val ,y_train,y_val = train_test_split(X_train_val,y_train_val,test_size=size_ratio,stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a39ecca0-4271-4678-9cd1-9d2feb51ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "X_val = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7d34caa9-41bd-4e90-8b27-59eea379666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val,dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train,dtype=torch.long)\n",
    "y_test = torch.tensor(y_test,dtype=torch.long)\n",
    "y_val = torch.tensor(y_val,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58bd458c-10c0-41b1-8098-27140837d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(X_train,y_train)\n",
    "test_ds = TensorDataset(X_test,y_test)\n",
    "val_ds = TensorDataset(X_val,y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds,batch_size=32)\n",
    "test_loader = DataLoader(test_ds,batch_size=32)\n",
    "val_loader = DataLoader(val_ds,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8ae55c00-aad0-4cf3-b6fd-1dac2dd98968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "input_dim = X_train.shape[1]\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(input_dim, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 1)  \n",
    "    )\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "77268ede-abad-436a-baee-e1244c61bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer =  torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "45984ee1-10c8-499f-9c70-4fa395f53a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                       0\n",
       "Gender                    0\n",
       "Admission Test Score      0\n",
       "High School Percentage    0\n",
       "City                      0\n",
       "Admission Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6e61276e-5f66-4183-b2b6-65e7e2b28a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: nan\n",
      "Epoch 2/50, Loss: nan\n",
      "Epoch 3/50, Loss: nan\n",
      "Epoch 4/50, Loss: nan\n",
      "Epoch 5/50, Loss: nan\n",
      "Epoch 6/50, Loss: nan\n",
      "Epoch 7/50, Loss: nan\n",
      "Epoch 8/50, Loss: nan\n",
      "Epoch 9/50, Loss: nan\n",
      "Epoch 10/50, Loss: nan\n",
      "Epoch 11/50, Loss: nan\n",
      "Epoch 12/50, Loss: nan\n",
      "Epoch 13/50, Loss: nan\n",
      "Epoch 14/50, Loss: nan\n",
      "Epoch 15/50, Loss: nan\n",
      "Epoch 16/50, Loss: nan\n",
      "Epoch 17/50, Loss: nan\n",
      "Epoch 18/50, Loss: nan\n",
      "Epoch 19/50, Loss: nan\n",
      "Epoch 20/50, Loss: nan\n",
      "Epoch 21/50, Loss: nan\n",
      "Epoch 22/50, Loss: nan\n",
      "Epoch 23/50, Loss: nan\n",
      "Epoch 24/50, Loss: nan\n",
      "Epoch 25/50, Loss: nan\n",
      "Epoch 26/50, Loss: nan\n",
      "Epoch 27/50, Loss: nan\n",
      "Epoch 28/50, Loss: nan\n",
      "Epoch 29/50, Loss: nan\n",
      "Epoch 30/50, Loss: nan\n",
      "Epoch 31/50, Loss: nan\n",
      "Epoch 32/50, Loss: nan\n",
      "Epoch 33/50, Loss: nan\n",
      "Epoch 34/50, Loss: nan\n",
      "Epoch 35/50, Loss: nan\n",
      "Epoch 36/50, Loss: nan\n",
      "Epoch 37/50, Loss: nan\n",
      "Epoch 38/50, Loss: nan\n",
      "Epoch 39/50, Loss: nan\n",
      "Epoch 40/50, Loss: nan\n",
      "Epoch 41/50, Loss: nan\n",
      "Epoch 42/50, Loss: nan\n",
      "Epoch 43/50, Loss: nan\n",
      "Epoch 44/50, Loss: nan\n",
      "Epoch 45/50, Loss: nan\n",
      "Epoch 46/50, Loss: nan\n",
      "Epoch 47/50, Loss: nan\n",
      "Epoch 48/50, Loss: nan\n",
      "Epoch 49/50, Loss: nan\n",
      "Epoch 50/50, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(1), y_batch.float())\n",
    "        loss.backward()     \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3a94345f-1666-4f3f-b3b2-31a58b315edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.6945 | Train Acc: 0.5118 | Val Loss: 0.7006 | Val Acc: 0.4667\n",
      "Epoch 2/50 | Train Loss: 0.6908 | Train Acc: 0.4909 | Val Loss: 0.7014 | Val Acc: 0.4667\n",
      "Epoch 3/50 | Train Loss: 0.6886 | Train Acc: 0.5014 | Val Loss: 0.7020 | Val Acc: 0.4667\n",
      "Epoch 4/50 | Train Loss: 0.6867 | Train Acc: 0.5118 | Val Loss: 0.7026 | Val Acc: 0.4333\n",
      "Epoch 5/50 | Train Loss: 0.6849 | Train Acc: 0.5326 | Val Loss: 0.7032 | Val Acc: 0.4333\n",
      "Epoch 6/50 | Train Loss: 0.6831 | Train Acc: 0.5575 | Val Loss: 0.7039 | Val Acc: 0.4333\n",
      "Epoch 7/50 | Train Loss: 0.6814 | Train Acc: 0.5367 | Val Loss: 0.7047 | Val Acc: 0.4333\n",
      "Epoch 8/50 | Train Loss: 0.6797 | Train Acc: 0.5471 | Val Loss: 0.7055 | Val Acc: 0.4333\n",
      "Epoch 9/50 | Train Loss: 0.6779 | Train Acc: 0.5720 | Val Loss: 0.7065 | Val Acc: 0.4333\n",
      "Epoch 10/50 | Train Loss: 0.6761 | Train Acc: 0.6259 | Val Loss: 0.7076 | Val Acc: 0.4667\n",
      "Epoch 11/50 | Train Loss: 0.6742 | Train Acc: 0.6259 | Val Loss: 0.7087 | Val Acc: 0.4000\n",
      "Epoch 12/50 | Train Loss: 0.6723 | Train Acc: 0.6218 | Val Loss: 0.7098 | Val Acc: 0.3667\n",
      "Epoch 13/50 | Train Loss: 0.6703 | Train Acc: 0.6218 | Val Loss: 0.7110 | Val Acc: 0.3333\n",
      "Epoch 14/50 | Train Loss: 0.6683 | Train Acc: 0.6322 | Val Loss: 0.7122 | Val Acc: 0.3667\n",
      "Epoch 15/50 | Train Loss: 0.6661 | Train Acc: 0.6322 | Val Loss: 0.7134 | Val Acc: 0.3667\n",
      "Epoch 16/50 | Train Loss: 0.6638 | Train Acc: 0.6467 | Val Loss: 0.7146 | Val Acc: 0.3667\n",
      "Epoch 17/50 | Train Loss: 0.6615 | Train Acc: 0.6612 | Val Loss: 0.7159 | Val Acc: 0.3667\n",
      "Epoch 18/50 | Train Loss: 0.6590 | Train Acc: 0.6612 | Val Loss: 0.7173 | Val Acc: 0.3667\n",
      "Epoch 19/50 | Train Loss: 0.6565 | Train Acc: 0.6612 | Val Loss: 0.7188 | Val Acc: 0.3333\n",
      "Epoch 20/50 | Train Loss: 0.6538 | Train Acc: 0.6508 | Val Loss: 0.7203 | Val Acc: 0.3000\n",
      "Epoch 21/50 | Train Loss: 0.6510 | Train Acc: 0.6612 | Val Loss: 0.7216 | Val Acc: 0.3000\n",
      "Epoch 22/50 | Train Loss: 0.6480 | Train Acc: 0.6612 | Val Loss: 0.7230 | Val Acc: 0.3000\n",
      "Epoch 23/50 | Train Loss: 0.6448 | Train Acc: 0.6612 | Val Loss: 0.7246 | Val Acc: 0.3000\n",
      "Epoch 24/50 | Train Loss: 0.6416 | Train Acc: 0.6612 | Val Loss: 0.7265 | Val Acc: 0.2667\n",
      "Epoch 25/50 | Train Loss: 0.6384 | Train Acc: 0.6508 | Val Loss: 0.7285 | Val Acc: 0.2667\n",
      "Epoch 26/50 | Train Loss: 0.6350 | Train Acc: 0.6508 | Val Loss: 0.7306 | Val Acc: 0.2667\n",
      "Epoch 27/50 | Train Loss: 0.6314 | Train Acc: 0.6612 | Val Loss: 0.7326 | Val Acc: 0.2667\n",
      "Epoch 28/50 | Train Loss: 0.6278 | Train Acc: 0.6716 | Val Loss: 0.7345 | Val Acc: 0.2667\n",
      "Epoch 29/50 | Train Loss: 0.6242 | Train Acc: 0.6676 | Val Loss: 0.7365 | Val Acc: 0.2667\n",
      "Epoch 30/50 | Train Loss: 0.6205 | Train Acc: 0.6676 | Val Loss: 0.7386 | Val Acc: 0.2667\n",
      "Epoch 31/50 | Train Loss: 0.6167 | Train Acc: 0.6572 | Val Loss: 0.7408 | Val Acc: 0.2667\n",
      "Epoch 32/50 | Train Loss: 0.6129 | Train Acc: 0.6467 | Val Loss: 0.7432 | Val Acc: 0.3000\n",
      "Epoch 33/50 | Train Loss: 0.6090 | Train Acc: 0.6467 | Val Loss: 0.7457 | Val Acc: 0.3000\n",
      "Epoch 34/50 | Train Loss: 0.6050 | Train Acc: 0.6467 | Val Loss: 0.7480 | Val Acc: 0.3000\n",
      "Epoch 35/50 | Train Loss: 0.6009 | Train Acc: 0.6612 | Val Loss: 0.7506 | Val Acc: 0.3000\n",
      "Epoch 36/50 | Train Loss: 0.5969 | Train Acc: 0.6508 | Val Loss: 0.7532 | Val Acc: 0.3000\n",
      "Epoch 37/50 | Train Loss: 0.5927 | Train Acc: 0.6612 | Val Loss: 0.7559 | Val Acc: 0.3000\n",
      "Epoch 38/50 | Train Loss: 0.5886 | Train Acc: 0.6612 | Val Loss: 0.7586 | Val Acc: 0.3000\n",
      "Epoch 39/50 | Train Loss: 0.5844 | Train Acc: 0.6612 | Val Loss: 0.7614 | Val Acc: 0.3000\n",
      "Epoch 40/50 | Train Loss: 0.5802 | Train Acc: 0.6821 | Val Loss: 0.7644 | Val Acc: 0.3000\n",
      "Epoch 41/50 | Train Loss: 0.5761 | Train Acc: 0.6716 | Val Loss: 0.7674 | Val Acc: 0.3333\n",
      "Epoch 42/50 | Train Loss: 0.5718 | Train Acc: 0.6716 | Val Loss: 0.7704 | Val Acc: 0.3333\n",
      "Epoch 43/50 | Train Loss: 0.5676 | Train Acc: 0.6861 | Val Loss: 0.7735 | Val Acc: 0.3333\n",
      "Epoch 44/50 | Train Loss: 0.5633 | Train Acc: 0.7070 | Val Loss: 0.7764 | Val Acc: 0.3667\n",
      "Epoch 45/50 | Train Loss: 0.5591 | Train Acc: 0.7070 | Val Loss: 0.7793 | Val Acc: 0.3667\n",
      "Epoch 46/50 | Train Loss: 0.5548 | Train Acc: 0.7215 | Val Loss: 0.7822 | Val Acc: 0.3667\n",
      "Epoch 47/50 | Train Loss: 0.5504 | Train Acc: 0.7215 | Val Loss: 0.7852 | Val Acc: 0.3667\n",
      "Epoch 48/50 | Train Loss: 0.5460 | Train Acc: 0.7215 | Val Loss: 0.7882 | Val Acc: 0.3667\n",
      "Epoch 49/50 | Train Loss: 0.5418 | Train Acc: 0.7215 | Val Loss: 0.7911 | Val Acc: 0.3667\n",
      "Epoch 50/50 | Train Loss: 0.5375 | Train Acc: 0.7215 | Val Loss: 0.7942 | Val Acc: 0.3667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = df.drop(columns=\"Name\")\n",
    "df.loc[df[\"Age\"] < 0, \"Age\"] = np.nan\n",
    "df = df.dropna(subset=[\"Admission Status\"])\n",
    "\n",
    "X = df.drop(columns=\"Admission Status\")\n",
    "y = df[\"Admission Status\"]\n",
    "\n",
    "label = LabelEncoder()\n",
    "y_encoded = label.fit_transform(y)\n",
    "\n",
    "num_cols = [\"Age\",\"Admission Test Score\",\"High School Percentage\"]\n",
    "cat_cols = [\"Gender\",\"City\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        \n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(drop=\"first\"))\n",
    "        ]), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---------- Splits ----------\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "size_ratio = 0.2 / 0.8\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val,\n",
    "    test_size=size_ratio,\n",
    "    stratify=y_train_val,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ---------- Fit ONLY on train ----------\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val   = preprocessor.transform(X_val)\n",
    "X_test  = preprocessor.transform(X_test)\n",
    "\n",
    "# ---------- To tensors ----------\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val   = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val   = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_test  = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train,y_train), batch_size=32)\n",
    "val_loader   = DataLoader(TensorDataset(X_val,y_val), batch_size=32)\n",
    "test_loader  = DataLoader(TensorDataset(X_test,y_test), batch_size=32)\n",
    "\n",
    "# ---------- Model ----------\n",
    "input_dim = X_train.shape[1]\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32,1)\n",
    ")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def get_accuracy(outputs, targets):\n",
    "    probs = torch.sigmoid(outputs)\n",
    "    preds = (probs >= 0.5).float()\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "\n",
    "# ---------- Training ----------\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---------- TRAIN ----------\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(xb).squeeze(1)\n",
    "\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += get_accuracy(outputs, yb)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    # ---------- VALIDATION ----------\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            outputs = model(xb).squeeze(1)\n",
    "            loss = criterion(outputs, yb)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_acc += get_accuracy(outputs, yb)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} \"\n",
    "        f\"| Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
    "        f\"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "491ee27d-9346-4aa1-8c4a-b12030f63958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8550 | Test Accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        outputs = model(xb).squeeze(1)\n",
    "        loss = criterion(outputs, yb)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        test_acc += get_accuracy(outputs, yb)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_acc /= len(test_loader)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bb456-6ca4-4e6a-b38e-e173d6f0f87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4053f1-569a-4469-94f1-d0a001f6ef99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
